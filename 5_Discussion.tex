\chapter{Discussion}
\label{Discussion}

% Research qs were answered
Through experiments \ref{Expt_1} and \ref{Expt_2}, we show that the paired Pix2Pix approach can generate higher quality images as compared to unpaired CycleGAN, although at the cost of acquiring and preparing the ground truth images. Among the two CycleGAN systems, CycleGAN-balanced was able to circumvent the non-invertibility issue of CycleGAN-naive due to its design modification, and produced better results as indicated by both quantitative and qualitative analyses. Our quantitative evaluation of the synthetic HX4-PET images involved using a set of six full-reference metrics that measured broadly two different aspects of the images -- voxel-wise accuracy and (local and global) image statistics. Furthermore, each metric has its own unique property and since the ``quality" of an image is multifaceted in nature, using a population of such metrics for image assessment can more effectively capture image quality as compared to using a smaller subset of them. We thereby address our first research question. In \ref{cycelgan_convergence}, we perform an analysis of CycleGAN training losses over the training period and observe that the CycleGAN-balanced model was more stable and displayed better convergence properties as opposed to the CycleGAN-naive model which diverged away from its objectives. The validation metrics collectively reflected up to a great extent the similar trends as the convergence parameters, thereby providing an answer to our third research question. Finally, through experiment \ref{Expt_3}, we address our second research question by identifying and performing clinically useful downstream tasks to determine the value of our synthetic HX4-PET images. Tumor hypoxia measurement as derived from synthetic images predicted by Pix2Pix showed poor 
As supplementary material, we supply the \textit{WandB} training reports for the depth-estimation task (experiment \ref{Expt_1}) \footnote{Training report for the depth-estimation task: \url{https://bit.ly/3x452Qi}} and for the HX4-PET synthesis task (experiment \ref{Expt_2}) \footnote{Training report for the HX4-PET synthesis task: \url{https://bit.ly/35Y8dx2}} which include training losses, validation metrics and intermediate outputs of the models.

% Some limitations, and opportunities for future work (stuff to do after thesis):
%   1. Dataset size -- larger training set to train better models, larger validation set to test properly
%   2. CycleGANs appeared to focus more on FDG features. Would be nice to see through an ablation study whether or not they really use CT features. One way to do this is taking the same trained models, turning off the CT signal in their input and performing inference.
%   3. With metrics - Need to consult more theoretical literature to understand their mathematical properties. This would allow choosing better and more diverse metrics to use and evaluate with the voting method.
%   4. Turing test
There are several limitations of this thesis which can provide opportunities for future work. First, the small size of our Maastro Lung HX4-PET dataset was a serious limitation on model training and validation. A larger training dataset would allow training better translation models, and a sufficiently large and diverse validation dataset would enable more effective evaluation of the models. Second, it was observed that both the CycleGAN models predicted tumor hypoxia patterns which closely resembled the FDG uptake signatures rather than the actual spatial distribution of hypoxia. The models might have learned to heavily rely on FDG-PET features, while ignoring CT information. It would be interesting to verify this by performing an ablation study on these models. This could be conducted, for instance, by performing inference on the fully trained models with the CT signal set to zero value and observing the generator outputs. Third, the quality assessment of the synthetic HX4-PET images was performed using a set of six general-purpose image quality and similarity metrics that were logically chosen. However, this portfolio of evaluation metrics can be improved. It would be valuable to consult theoretical literature on image metrics and understand in a greater depth their mathematical properties. This would help in selecting more suitable and diverse metrics thereby improving the effectiveness of the consensus-based image evaluation. Fourth, as an extension of the simple automated clinical evaluation performed in experiment \ref{Expt_3}, a version of the Turing test can be performed by presenting the synthetic HX4-PET images to a radiation oncologist, with a certain clinically relevant goal, for instance, performing a prognosis based on the synthetic images and comparing with the prognosis done based on the ground truth.


% Fine tuning stuff (questionable. don't include)
% Second, the Pix2Pix model failed in accurately predicting tumor hypoxia and produced high-frequency noise patterns in the tumor region, although its synthetic HX4-PET images were of an overall high quality. In addition to the registration-related issues, this failure can also be attributed to model training. In addition to using a larger training dataset as a possible solution to reducing these artifacts, it would be interesting to investigate into \textit{fine tuning} the trained Pix2Pix model using the existing dataset. This could be performed, for instance, by first using a patch-sampling strategy that focuses more on the tumor vicinity. Then, the weights of the Pix2Pix generator's encoder (which is its feature extractor) could be frozen while updating only its decoder (which is its image synthesizer). The intuition behind this is that, in doing so, the noise patterns can potentially be reduced since they caused during the upsampling operations used the decoder path, and that this by learning better upsampling kernels


% Expt 3 stuff (need this? probably not)
% We argue that although none of our models' synthetic HX4-PET was clinically satisfactory, paired translation approaches such as Pix2Pix that assume voxel-wise alignment are bound to produce inaccuracies in their images at a scale of the tumor.
% In our dataset, HX4-PET scans for all patient were acquired on a different day from FDG-PET and pCT acquisition. A problem with tumor hypoxia is the fact that the hypoxic region has a tendency to change over time, even over a period of hours [cite ...]. Zegers et al. \cite{zegers2013hypoxia} raise this argument to explain the relatively low \textit{voxel-level} correlation they observed between FDG-PET and HX4-PET SUV values despite a significant correlation on \textit{tumor-level} properties between the two modalities. It is possible that in our data, the state of the tumor captured by FDG-PET/pCT might not correspond perfectly to its state captured by HX4-PET. In such a case, even if the HX4-PET image were to be perfectly registered over pCT and FDG-PET, a supervised method that assumes voxel-level correspondence would be less effective, to say the least. In this view, it could then be possible that the hypoxia patterns predicted by the CycleGANs, although not matching the ground truth, might reflect the ``actual" hypoxia distribution.