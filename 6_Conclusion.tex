\chapter{Conclusion}
\label{Conclusion}

In this work, we formulated the problem of predicting hypoxia from FDG-PET and CT scans as image-to-image translation and investigated image translation GANs for synthesizing full HX4-PET images from the multimodal input. Using the paired Pix2Pix and the unpaired CycleGAN, we observed that the paired approach produces superior quality images both in our simulated translation task and in the HX4-PET synthesis task. We argued that the naive application of CycleGAN to the HX4-PET synthesis task has a conceptual flaw related to non-invertibility of the inter-domain mappings, and proposed an alternative strategy to circumvent this problem while still relying on unpaired training data. This modified CycleGAN system showed substantial performance improvement over the default CycleGAN in terms of image quality. To assess the quality of the synthetic HX4-PET images in a comprehensive manner, we constructed a set of six measures of image quality and image similarity that measure broadly two different aspects of the images -- voxel-wise accuracy and (local and global) image statistics. A systematic visual inspection of the synthetic HX4-PET images validated the assessment of these metrics and also revealed common failure modes for each model. Images from Pix2Pix contained, on average, the least amount of degradation and artifacts, although they suffered from structural breaks in specific areas. These faults can be attributed to the supervised training of Pix2Pix which used ground truth images containing registration imperfections. Despite the clear image-quality-based performance differences across the three image translation models, the clinical evaluation of their synthetic images conducted via tumor hypoxia quantification tasks produced mixed and inconclusive results. These results were overall unsatisfactory indicating the insufficiency of the models in meeting the clinical requirements. The potential for clinical implementation of these image translation methods needs to be further investigated using larger and more diverse training and validation datasets. Between the paired and unpaired translation approaches, the latter could be more suitable due to their considerably more lenient data requirements and their lack of direct dependence on spatially aligned ground truth images that makes them immune to issues caused by misaligned training data.